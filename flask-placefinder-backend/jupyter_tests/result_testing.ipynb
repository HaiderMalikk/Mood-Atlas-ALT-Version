{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HERE TEST USING THE 'RESULTS' OBJECT FROM SAMPLE DATA JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: ignore the first object in json i.e 'final results.json' as its the city itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load env file with api key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv() # reading all vaiables from .env file (api key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load llm and test it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAPI_API_KEY = os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=OPENAPI_API_KEY, temperature=0.2, max_tokens=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.invoke(\"if active respond with active\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load JSON and print it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and read the JSON file\n",
    "with open('./final_results.json', 'r') as file:\n",
    "    results_data = json.load(file)\n",
    "# Print the data\n",
    "print(results_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Test Objects and Properties From json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place = results_data[1]  # first location \n",
    "location = place['geometry']['location']\n",
    "print(\"place data\")\n",
    "print(place)\n",
    "print(\"location data\")\n",
    "print(location)\n",
    "lat, lon = location['lat'], location['lng']\n",
    "print(f\"Latitude: {lat}, Longitude: {lon}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate over objects and get their attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total places:\", len(results_data) - 1)\n",
    "results_data.pop(0)\n",
    "counter = 0\n",
    "formatted_places = {}\n",
    "\n",
    "for place in results_data:\n",
    "    name = place['name']\n",
    "    formatted_places[counter] = name\n",
    "    print(f\"Key: {counter}, Value: {formatted_places[counter]}\")\n",
    "    counter += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing The LLM promt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "usermood = \"happy\"\n",
    "userhobby = \"Sports\"\n",
    "useractivities = \"Eating\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are a place selector your job is to find a place for the attributes of the user which are as follows:\n",
    "Users Mood: {mood}, Users Hobbies: {hobby}, Users Activities: {activities}\n",
    "\n",
    "You are also given a key value pair as follows: Key = place number and Value = place name. \n",
    "Your job is too find the best place for the user based on the given attributes.\n",
    "you do this by looking at the name of the place which is the value.\n",
    "When you find the right place return its key your answer must be a single integer in the range of keys given in the problem.\n",
    "YOU MUST RETURN A VALID INTEGER AND NOTHING ELSE, EVEN IF THE USER HAS NO MATCHING PLACE RETURN YOU BEST GUESS.\n",
    "Here is the list of places:\n",
    "{places}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template) # creating the prompt using the chat prompt template library\n",
    "final_prompt = prompt.format(mood = usermood, hobby = userhobby, activities = useractivities, places = formatted_places) # passing in the context and question to the prompt\n",
    "print(final_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke LLM with final promt with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm.invoke(final_prompt)\n",
    "place_number = result.content\n",
    "print(place_number)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-02",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
